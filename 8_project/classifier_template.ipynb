{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from xgboost import XGBClassifier, XGBRFClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, f1_score, matthews_corrcoef\n",
    "from sklearn.preprocessing import label_binarize\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from lstm import LSTMNet, LSTMNetParams, prepare_data as prepare_data_lstm\n",
    "\n",
    "from util.encoding import encode\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/features.csv\")\n",
    "X = df.iloc[:, 2:-1]  # skip index and name\n",
    "\n",
    "y = df[\"label\"]  # 10 genres\n",
    "y, code = encode(y) # encode labels to integers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### NORMALIZE X ####\n",
    "# Normalize so everything is on the same scale.\n",
    "\n",
    "cols = X.columns\n",
    "std_scaler = sklearn.preprocessing.StandardScaler()\n",
    "np_scaled = std_scaler.fit_transform(X)\n",
    "\n",
    "# new data frame with the new scaled data. \n",
    "X = pd.DataFrame(np_scaled, columns = cols)\n",
    "\n",
    "# train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_assess(model, X_train, X_test, y_train, y_test, title=\"Default\"):\n",
    "    \"\"\"\n",
    "    Fit given model and assess its performance regarding accuracy, F1 score, AUC score and\n",
    "    matthews correlation coefficient\n",
    "    \"\"\"\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average=\"weighted\")\n",
    "\n",
    "    # binarize labels for multi class roc score\n",
    "    labels = list(set(y))\n",
    "    y_test_bin = label_binarize(y_test, classes=labels)\n",
    "    y_pred_bin = label_binarize(y_pred, classes=labels)\n",
    "    roc = roc_auc_score(y_test_bin, y_pred_bin, average=\"weighted\", multi_class=\"ovo\")\n",
    "    matt_cor = matthews_corrcoef(y_test, y_pred)\n",
    "\n",
    "    print(\n",
    "        f\"{title}:\\n  Acc: {round(acc, 2)}\\n  F1: {round(f1, 2)}\\n  AUC score: {round(roc, 2)}\\n  Matth. corr. coeff.: {round(matt_cor, 2)}\"\n",
    "    )\n",
    "    return acc, f1, roc, matt_cor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifier experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save experiment results\n",
    "df_res = pd.DataFrame(columns=[\"classifier\", \"accuracy\", \"F1\", \"AUC\", \"MCC\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log. Regression:\n",
      "  Acc: 0.59\n",
      "  F1: 0.6\n",
      "  ROC score: 0.77\n",
      "  Matth. corr. coeff.: 0.55\n"
     ]
    }
   ],
   "source": [
    "log_reg = LogisticRegression(random_state=0, max_iter=500).fit(X_train, y_train)\n",
    "log_reg_acc, log_reg_f1, log_reg_auc, log_reg_mcc = model_assess(\n",
    "    log_reg, X_train, X_test, y_train, y_test, title=\"Log. Regression\"\n",
    ")\n",
    "df_res.loc[len(df_res)] = [\"Logistic regression\", log_reg_acc, log_reg_f1, log_reg_auc, log_reg_mcc]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gaussian Naive bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gaussian naive bayes:\n",
      "  Acc: 0.45\n",
      "  F1: 0.41\n",
      "  ROC score: 0.7\n",
      "  Matth. corr. coeff.: 0.4\n"
     ]
    }
   ],
   "source": [
    "gnb = GaussianNB()\n",
    "gnb_acc, gnb_f1, gnb_auc, gnb_mcc = model_assess(\n",
    "    gnb, X_train, X_test, y_train, y_test, title=\"Gaussian naive bayes\"\n",
    ")\n",
    "df_res.loc[len(df_res)] = [\"Gaussian naive bayes\", gnb_acc, gnb_f1, gnb_auc, gnb_mcc]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Support vector classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gaussian naive bayes:\n",
      "  Acc: 0.69\n",
      "  F1: 0.69\n",
      "  ROC score: 0.83\n",
      "  Matth. corr. coeff.: 0.66\n"
     ]
    }
   ],
   "source": [
    "svc_clf = SVC(gamma=\"auto\")\n",
    "svc_acc, svc_f1, svc_auc, svc_mcc = model_assess(\n",
    "    svc_clf, X_train, X_test, y_train, y_test, title=\"SVC\"\n",
    ")\n",
    "df_res.loc[len(df_res)] = [\"SVC\", svc_acc, svc_f1, svc_auc, svc_mcc]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random forest:\n",
      "  Acc: 0.69\n",
      "  F1: 0.69\n",
      "  ROC score: 0.83\n",
      "  Matth. corr. coeff.: 0.66\n"
     ]
    }
   ],
   "source": [
    "forest_clf = RandomForestClassifier()\n",
    "forest_acc, forest_f1, forest_auc, forest_mcc = model_assess(\n",
    "    forest_clf, X_train, X_test, y_train, y_test, title=\"Random forest\"\n",
    ")\n",
    "df_res.loc[len(df_res)] = [\"Random forest\", forest_acc, forest_f1, forest_auc, forest_mcc]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ivo/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost:\n",
      "  Acc: 0.7\n",
      "  F1: 0.7\n",
      "  ROC score: 0.83\n",
      "  Matth. corr. coeff.: 0.67\n"
     ]
    }
   ],
   "source": [
    "xgb = XGBClassifier(\n",
    "    n_estimators=1000,\n",
    "    booster=\"gbtree\",\n",
    "    learning_rate=0.04,\n",
    "    eval_metric=\"mlogloss\",\n",
    "    random_state=42,\n",
    ")\n",
    "xgb_acc, xgb_f1, xgb_auc, xgb_mcc = model_assess(\n",
    "    xgb, X_train, X_test, y_train, y_test, title=\"XGBoost\"\n",
    ")\n",
    "df_res.loc[len(df_res)] = [\"XGBoost\", xgb_acc, xgb_f1, xgb_auc, xgb_mcc]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ivo/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost:\n",
      "  Acc: 0.68\n",
      "  F1: 0.67\n",
      "  ROC score: 0.82\n",
      "  Matth. corr. coeff.: 0.64\n"
     ]
    }
   ],
   "source": [
    "xgbrf = XGBRFClassifier(\n",
    "    n_estimators=1000,\n",
    "    booster=\"gbtree\",\n",
    "    learning_rate=0.04,\n",
    "    objective=\"multi:softmax\",\n",
    "    eval_metric=\"mlogloss\",\n",
    "    random_state=42,\n",
    ")\n",
    "xgbrf_acc, xgbrf_f1, xgbrf_auc, xgbrf_mcc = model_assess(\n",
    "    xgbrf, X_train, X_test, y_train, y_test, title=\"XGBoost random forests\"\n",
    ")\n",
    "df_res.loc[len(df_res)] = [\"XGBoost random forests\", xgbrf_acc, xgbrf_f1, xgbrf_auc, xgbrf_mcc]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLP Sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP:\n",
      "  Acc: 0.73\n",
      "  F1: 0.73\n",
      "  ROC score: 0.85\n",
      "  Matth. corr. coeff.: 0.7\n"
     ]
    }
   ],
   "source": [
    "mlp = MLPClassifier(\n",
    "    random_state=42,\n",
    "    max_iter=1000,\n",
    "    activation=\"tanh\",\n",
    "    solver=\"adam\",\n",
    "    alpha=0.0001,\n",
    "    learning_rate=\"adaptive\",\n",
    "    learning_rate_init=0.01,\n",
    ")\n",
    "mlp_acc, mlp_f1, mlp_auc, mlp_mcc = model_assess(\n",
    "    mlp, X_train, X_test, y_train, y_test, title=\"MLP\"\n",
    ")\n",
    "df_res.loc[len(df_res)] = [\"MLP\", mlp_acc, mlp_f1, mlp_auc, mlp_mcc]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSTM Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM:\n",
      "  Acc: 0.69\n",
      "  F1: 0.69\n",
      "  AUC score: 0.83\n",
      "  Matth. corr. coeff.: 0.66\n"
     ]
    }
   ],
   "source": [
    "X_train_t, X_test_t, y_train_t, y_test_t = prepare_data_lstm(\n",
    "    X_train, X_test, y_train, y_test\n",
    ")\n",
    "lstm_params = LSTMNetParams(\n",
    "    num_epochs=2000,\n",
    "    learning_rate=0.01,\n",
    "    dropout=0.3,\n",
    "    input_size=29,\n",
    "    hidden_size=20,\n",
    "    hidden_layer=50,\n",
    "    num_layers=1,\n",
    "    num_classes=10,\n",
    "    seq_length=X_train_t.shape[1],\n",
    "    tensorboard=False\n",
    ")\n",
    "lstm = LSTMNet(lstm_params)\n",
    "lstm_acc, lstm_f1, lstm_auc, lstm_mcc = model_assess(\n",
    "    lstm, X_train_t, X_test_t, y_train_t, y_test_t, title=\"LSTM\"\n",
    ")\n",
    "df_res.loc[len(df_res)] = [\"LSTM\", lstm_acc, lstm_f1, lstm_auc, lstm_mcc]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN Resnet\n",
    "\n",
    "TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res.to_csv(\"data/classifier_results.csv\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "744438a286f552de89f21840df11d95eed1d912f7f5940de34928fec5bf381d0"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
