{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from xgboost import XGBClassifier, XGBRFClassifier\n",
    "from xgboost import plot_tree, plot_importance\n",
    "\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, f1_score, matthews_corrcoef\n",
    "from sklearn.preprocessing import label_binarize\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Helper functions to encode and decode string labels to integers\n",
    "\"\"\"\n",
    "\n",
    "def encode(y):\n",
    "    labels = y.unique()\n",
    "    # encode label map\n",
    "    code = {v: i for i, v in enumerate(labels)}\n",
    "\n",
    "    # encode labels to new vector\n",
    "    return list(map(lambda x: code[x], y)), code\n",
    "\n",
    "\n",
    "def decode(y, code):\n",
    "    keys = list(code.keys())\n",
    "    values = list(code.values())\n",
    "    return list(map(lambda x: keys[values.index(x)], y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/features_var_thres.csv\")\n",
    "X = df.iloc[:, 2:-1]  # skip index and name\n",
    "\n",
    "y = df[\"label\"]  # 10 genres\n",
    "y, code = encode(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### NORMALIZE X ####\n",
    "# Normalize so everything is on the same scale.\n",
    "\n",
    "cols = X.columns\n",
    "std_scaler = sklearn.preprocessing.StandardScaler()\n",
    "np_scaled = std_scaler.fit_transform(X)\n",
    "\n",
    "# new data frame with the new scaled data. \n",
    "X = pd.DataFrame(np_scaled, columns = cols)\n",
    "\n",
    "# train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_assess(model, X_train, X_test, y_train, y_test, title=\"Default\"):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average=\"weighted\")\n",
    "\n",
    "    # binarize labels for multi class roc score\n",
    "    labels = list(set(y))\n",
    "    y_test_bin = label_binarize(y_test, classes=labels)\n",
    "    y_pred_bin = label_binarize(y_pred, classes=labels)\n",
    "    roc = roc_auc_score(y_test_bin, y_pred_bin, average=\"weighted\", multi_class=\"ovo\")\n",
    "    matt_cor = matthews_corrcoef(y_test, y_pred)\n",
    "\n",
    "    print(\n",
    "        f\"{title}:\\n  Acc: {round(acc, 2)}\\n  F1: {round(f1, 2)}\\n  ROC score: {round(roc, 2)}\\n  Matth. corr. coeff.: {round(matt_cor, 2)}\"\n",
    "    )\n",
    "    return acc, f1, roc, matt_cor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log. Regression:\n",
      "  Acc: 0.54\n",
      "  F1: 0.53\n",
      "  ROC score: 0.74\n",
      "  Matth. corr. coeff.: 0.49\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.5366666666666666, 0.531945408790232, 0.7425931296330234)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression(random_state=0, max_iter=500).fit(X_train, y_train)\n",
    "model_assess(clf, X_train, X_test, y_train, y_test, title=\"Log. Regression\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC:\n",
      "  Acc: 0.63\n",
      "  F1: 0.63\n",
      "  ROC score: 0.79\n",
      "  Matth. corr. coeff.: 0.59\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.63, 0.6287606668348482, 0.7949669162093735)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svc_clf = SVC(gamma=\"auto\")\n",
    "model_assess(svc_clf, X_train, X_test, y_train, y_test, title=\"SVC\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ivo/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Gradient Booster:\n",
      "  Acc: 0.58\n",
      "  F1: 0.59\n",
      "  ROC score: 0.77\n",
      "  Matth. corr. coeff.: 0.54\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.5833333333333334, 0.5866160524081848, 0.7695172316832881)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb = XGBClassifier(n_estimators=1000, learning_rate=0.05, eval_metric=\"mlogloss\")\n",
    "model_assess(xgb, X_train, X_test, y_train, y_test, \"Cross Gradient Booster\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ivo/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Gradient Booster (Random Forest):\n",
      "  Acc: 0.53\n",
      "  F1: 0.52\n",
      "  ROC score: 0.74\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.5266666666666666, 0.5209247330955603, 0.7370149571376233)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgbrf = XGBRFClassifier(objective=\"multi:softmax\", eval_metric=\"mlogloss\")\n",
    "model_assess(\n",
    "    xgbrf, X_train, X_test, y_train, y_test, \"Cross Gradient Booster (Random Forest)\"\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "744438a286f552de89f21840df11d95eed1d912f7f5940de34928fec5bf381d0"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
